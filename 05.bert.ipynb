{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_pickle(f\"{data_dir}/imdb_data.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "seed = 11989\n",
    "\n",
    "train = imdb_data[imdb_data.data_set.str.lower() == 'train'].sample(sample_size, random_state = seed)\n",
    "test = imdb_data[imdb_data.data_set.str.lower() == 'test'].sample(sample_size, random_state = seed*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier:\n",
    "    \n",
    "    DEFAULT_CONFIG = {\n",
    "        'bert_url': 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1',\n",
    "        'output_dir': 'data/output',\n",
    "        'data_column': None,\n",
    "        'label_column': None,\n",
    "        'max_seq_length': 128,\n",
    "        'label_list': [0, 1]\n",
    "    }\n",
    "    \n",
    "    def __init__(self, **config):\n",
    "        self.config = BertClassifier.DEFAULT_CONFIG.copy()\n",
    "        self.config.update(config)\n",
    "        \n",
    "        # Make sure the output directory exists.\n",
    "        if not os.path.isdir(self.config['output_dir']):\n",
    "            os.makedirs(self.config['output_dir'])\n",
    "        \n",
    "        self._tokenizer = None\n",
    "        \n",
    "    def test(self, test):\n",
    "        pass\n",
    "        \n",
    "    def train(self, train):\n",
    "        train_features = self._feature_extractor(train)\n",
    "\n",
    "        label_list = [0, 1]\n",
    "        \n",
    "        #compute train steps and warmup steps from batch size\n",
    "        BATCH_SIZE = 32\n",
    "        LEARNING_RATE = 2e-5\n",
    "        NUM_TRAIN_EPOCHS = 3.0\n",
    "        # Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "        WARMUP_PROPORTION = 0.1\n",
    "\n",
    "        SAVE_CHECKPOINTS_STEPS = 500\n",
    "        SAVE_SUMMARY_STEPS = 100\n",
    "        # Compute # train and warmup steps from batch size\n",
    "\n",
    "        num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "        num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "        num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "        num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "        #output directory and number of checkpoint steps to to save\n",
    "        run_config = tf.estimator.RunConfig(\n",
    "            model_dir=self.config['output_dir'],\n",
    "            save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "            save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "        #created model function\n",
    "        model_fn = self._model_fn_builder(\n",
    "            num_labels=len(label_list),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "        estimator = tf.estimator.Estimator(\n",
    "            model_fn=model_fn,\n",
    "            config=run_config,\n",
    "            params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "        #create an input function for training; drop_remainder=True for TPUs\n",
    "        train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "            features=train_features,\n",
    "            seq_length=self.config['max_seq_length'],\n",
    "            is_training=True,\n",
    "            drop_remainder=False)\n",
    "\n",
    "        estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        return self.estimator\n",
    "        \n",
    "    def tokenizer(self):\n",
    "        if self._tokenizer is None:\n",
    "            with tf.Graph().as_default():\n",
    "                bert_module = hub.Module(self.config['bert_url'])\n",
    "                tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "                with tf.Session() as sess:\n",
    "                    vocab_file, do_lower_case = sess.run(\n",
    "                        [tokenization_info[\"vocab_file\"],\n",
    "                        tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "            self._tokenizer = bert.tokenization.FullTokenizer(\n",
    "                vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "        return self._tokenizer\n",
    "    \n",
    "            \n",
    "    def _feature_extractor(self, df):\n",
    "        inputs = df.apply(lambda row: bert.run_classifier.InputExample(\n",
    "            guid=None,\n",
    "            text_a = row[self.config['data_column']],\n",
    "            text_b = None,\n",
    "            label = row[self.config['label_column']]), axis=1)\n",
    "            \n",
    "        tokenizer = self.tokenizer()\n",
    "        label_list = [0, 1]\n",
    "        \n",
    "        \n",
    "        print(f\"{label_list} -> {self.config['max_seq_length']}\")\n",
    "        \n",
    "        return bert.run_classifier.convert_examples_to_features(\n",
    "            inputs,\n",
    "            label_list,\n",
    "            self.config['max_seq_length'],\n",
    "            tokenizer)\n",
    "    \n",
    "    def _create_model(self, is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
    "        bert_module = hub.Module(self.config['bert_url'], trainable=True)\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            segment_ids=segment_ids)\n",
    "        bert_outputs = bert_module(\n",
    "            inputs=bert_inputs,\n",
    "            signature=\"tokens\",\n",
    "            as_dict=True)\n",
    "\n",
    "        # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "        # Use \"sequence_outputs\" for token-level output.\n",
    "        output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "        hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "        # Create our own layer to tune for politeness data.\n",
    "        output_weights = tf.get_variable(\n",
    "            \"output_weights\", [num_labels, hidden_size],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "        with tf.variable_scope(\"loss\"):\n",
    "\n",
    "            # Dropout helps prevent overfitting\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "            logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "            logits = tf.nn.bias_add(logits, output_bias)\n",
    "            log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "            # Convert labels into one-hot encoding\n",
    "            one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "            predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "            # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "            if is_predicting:\n",
    "                return (predicted_labels, log_probs)\n",
    "\n",
    "            # If we're train/eval, compute loss between predicted and actual label\n",
    "            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "            loss = tf.reduce_mean(per_example_loss)\n",
    "            return (loss, predicted_labels, log_probs)\n",
    "\n",
    "    # model_fn_builder actually creates our model function\n",
    "    # using the passed parameters for num_labels, learning_rate, etc.\n",
    "    def _model_fn_builder(self, num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "        \n",
    "        # Calculate evaluation metrics. \n",
    "        def metric_fn(label_ids, predicted_labels):\n",
    "            accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "            f1_score = tf.contrib.metrics.f1_score(\n",
    "                label_ids,\n",
    "                predicted_labels)\n",
    "            auc = tf.metrics.auc(\n",
    "                label_ids,\n",
    "                predicted_labels)\n",
    "            recall = tf.metrics.recall(\n",
    "                label_ids,\n",
    "                predicted_labels)\n",
    "            precision = tf.metrics.precision(\n",
    "                label_ids,\n",
    "                predicted_labels) \n",
    "            true_pos = tf.metrics.true_positives(\n",
    "                label_ids,\n",
    "                predicted_labels)\n",
    "            true_neg = tf.metrics.true_negatives(\n",
    "                label_ids,\n",
    "                predicted_labels)   \n",
    "            false_pos = tf.metrics.false_positives(\n",
    "                label_ids,\n",
    "                predicted_labels)  \n",
    "            false_neg = tf.metrics.false_negatives(\n",
    "                label_ids,\n",
    "                predicted_labels)\n",
    "            return {\n",
    "                \"eval_accuracy\": accuracy,\n",
    "                \"f1_score\": f1_score,\n",
    "                \"auc\": auc,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"true_positives\": true_pos,\n",
    "                \"true_negatives\": true_neg,\n",
    "                \"false_positives\": false_pos,\n",
    "                \"false_negatives\": false_neg\n",
    "            }\n",
    "               \n",
    "        def create_model_fn_predicting(features, labels, mode, params):\n",
    "            input_ids = features[\"input_ids\"]\n",
    "            input_mask = features[\"input_mask\"]\n",
    "            segment_ids = features[\"segment_ids\"]\n",
    "            label_ids = features[\"label_ids\"]\n",
    "\n",
    "            (predicted_labels, log_probs) = self._create_model(\n",
    "                    True, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "        \n",
    "        def create_model_fn_not_predicting(features, labels, mode, params):\n",
    "            input_ids = features[\"input_ids\"]\n",
    "            input_mask = features[\"input_mask\"]\n",
    "            segment_ids = features[\"segment_ids\"]\n",
    "            label_ids = features[\"label_ids\"]\n",
    "            \n",
    "            (loss, predicted_labels, log_probs) = self._create_model(\n",
    "                False, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(\n",
    "                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "\n",
    "        def model_fn(features, labels, mode, params):\n",
    "            if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "                return create_model_fn_predicting(features, labels, mode, params)\n",
    "            else:\n",
    "                return create_model_fn_not_predicting(features, labels, mode, params)\n",
    "        \n",
    "        \n",
    "        # Return the actual model function in the closure\n",
    "        return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] -> 128\n",
      "0:00:03.372587\n"
     ]
    }
   ],
   "source": [
    "bc = BertClassifier(data_column='sentence', label_column='polarity')\n",
    "bc.train(train)\n",
    "bc.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1c56a802f98>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "bert_model_url = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def bert_create_tokenizer(bert_model_url):\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_model_url)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run(\n",
    "                [tokenization_info[\"vocab_file\"],\n",
    "                tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = bert_create_tokenizer(bert_model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_Classification(train, test, DATA_COLUMN, LABEL_COLUMN, OUTPUT_DIR):\n",
    "    \n",
    "    bert_model_hub=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" #need to write it as a function later\n",
    "    \n",
    "    train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "    \n",
    "   \n",
    "    tokenizer = bert_create_tokenizer(bert_model_url)\n",
    "\n",
    "    MAX_SEQ_LENGTH = 128\n",
    "    # Convert our train and test features to InputFeatures that BERT understands.\n",
    "    train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "    #compute train steps and warmup steps from batch size\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 2e-5\n",
    "    NUM_TRAIN_EPOCHS = 3.0\n",
    "    # Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "    WARMUP_PROPORTION = 0.1\n",
    "\n",
    "    SAVE_CHECKPOINTS_STEPS = 500\n",
    "    SAVE_SUMMARY_STEPS = 100\n",
    "    # Compute # train and warmup steps from batch size\n",
    "    \n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "    #output directory and number of checkpoint steps to to save\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        model_dir=OUTPUT_DIR,\n",
    "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "    #created model function\n",
    "    model_fn = model_fn_builder(\n",
    "      num_labels=len(label_list),\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      params={\"batch_size\": BATCH_SIZE})\n",
    "   \n",
    "    #create an input function for training; drop_remainder=True for TPUs\n",
    "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "    \n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "    #create an input function for testing; drop_remainder=True for TPUs\n",
    "    test_input_fn = run_classifier.input_fn_builder(\n",
    "        features=test_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "    \n",
    "    return {\n",
    "        \"Model_Evaluation\":result_dict, \n",
    "        \"Model\": estimator\n",
    "    }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
