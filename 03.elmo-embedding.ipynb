{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0604 14:26:13.054023 11724 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_pickle(f\"{data_dir}/imdb_data.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_set</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched this mini in the early eighties. Sam Waterson proved himself to be a great actor. In fact when he began Law and Order I was disappointed in him as it was not as powerful a role. Unfortun...</td>\n",
       "      <td>tt0163955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18916</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>If you like silly comedies like Airplane you'll love this movie! It's definitely in the style of Airplane and Scary Movie. A fun film! It has the strangest cast of characters all in the same movie...</td>\n",
       "      <td>tt0395669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_set  polarity  \\\n",
       "13640     test         1   \n",
       "18916     test         1   \n",
       "\n",
       "                                                                                                                                                                                                      sentence  \\\n",
       "13640  I watched this mini in the early eighties. Sam Waterson proved himself to be a great actor. In fact when he began Law and Order I was disappointed in him as it was not as powerful a role. Unfortun...   \n",
       "18916  If you like silly comedies like Airplane you'll love this movie! It's definitely in the style of Airplane and Scary Movie. A fun film! It has the strangest cast of characters all in the same movie...   \n",
       "\n",
       "        movie_id  \n",
       "13640  tt0163955  \n",
       "18916  tt0395669  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = imdb_data.sample(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using nltk for lemmatization.\n"
     ]
    }
   ],
   "source": [
    "max_words = 128\n",
    "\n",
    "text_http_re  = re.compile(r'http\\S+')\n",
    "text_digit_re = re.compile(r'[0-9]')\n",
    "text_html_re  = re.compile(r'<[^>]{0,20}>')\n",
    "text_punc_re  = re.compile('[' + re.escape('\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~') + ']')\n",
    "text_ws_re    = re.compile('\\s+')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text_http_re.sub('', text)\n",
    "    text = text_html_re.sub('', text)\n",
    "    text = text_digit_re.sub(' ', text)\n",
    "    text = text_punc_re.sub('', text)\n",
    "    text = text_ws_re.sub(' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def create_lemmatizer_spacy():\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    def lemmatize(text):\n",
    "        return ' '.join([token.lemma_ for token in nlp(text)][0:max_words])\n",
    "    \n",
    "    return lemmatize\n",
    "\n",
    "def create_lemmatizer_nltk():\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(text):\n",
    "        return ' '.join([lemmatizer.lemmatize(w) for w in text.split()][0:max_words])\n",
    "    \n",
    "    return lemmatize\n",
    "\n",
    "# Setup a lemmatize function, spacy.load may fail on windows for en.\n",
    "try:\n",
    "    lemmatize = create_lemmatizer_spacy()\n",
    "except:\n",
    "    print(\"Using nltk for lemmatization.\")\n",
    "    lemmatize = create_lemmatizer_nltk()\n",
    "            \n",
    "def process_text(text):\n",
    "    return lemmatize(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['clean_review'] = imdb_data.sentence.apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ELMo Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\bryanc\\source\\repos\\mlads-textembedding-bert-elmo-tutorial\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 14:27:35.636558 11724 deprecation.py:323] From c:\\users\\bryanc\\source\\repos\\mlads-textembedding-bert-elmo-tutorial\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Utility function to break sentences into batches.\n",
    "def batches(sentences, batch_size):\n",
    "    results = []\n",
    "    chunk = []\n",
    "    for s in sentences:\n",
    "        chunk.append(s)\n",
    "        if len(chunk) >= batch_size:\n",
    "            yield(chunk)\n",
    "            chunk = []\n",
    "    if len(chunk) > 0:\n",
    "        yield(chunk)\n",
    "\n",
    "def elmo_create_embedding_extractor(module, batch_size=20):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module, trainable=True)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "        \n",
    "    def extract(_sentences):\n",
    "        results = []\n",
    "        for s_batch in batches(_sentences, batch_size):\n",
    "            results.extend(session.run(embeddings, { sentences: s_batch }))\n",
    "            print(f\"[{datetime.now()}] Extracted {len(results)}\")\n",
    "        return results\n",
    "\n",
    "    return extract\n",
    "\n",
    "elmo_get_embedding = elmo_create_embedding_extractor(\"https://tfhub.dev/google/elmo/2\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-04 14:28:55.533996] Extracted 50\n",
      "[2019-06-04 14:29:47.236447] Extracted 100\n",
      "[2019-06-04 14:30:37.786700] Extracted 150\n",
      "[2019-06-04 14:31:28.215075] Extracted 200\n",
      "[2019-06-04 14:32:20.365033] Extracted 250\n",
      "[2019-06-04 14:33:11.260297] Extracted 300\n",
      "[2019-06-04 14:34:02.972305] Extracted 350\n",
      "[2019-06-04 14:34:54.654950] Extracted 400\n",
      "[2019-06-04 14:35:46.315738] Extracted 450\n",
      "[2019-06-04 14:36:36.021616] Extracted 500\n",
      "[2019-06-04 14:37:26.341114] Extracted 550\n",
      "[2019-06-04 14:38:19.087696] Extracted 600\n",
      "[2019-06-04 14:39:11.035528] Extracted 650\n",
      "[2019-06-04 14:40:01.452119] Extracted 700\n",
      "[2019-06-04 14:40:52.376668] Extracted 750\n",
      "[2019-06-04 14:41:44.998869] Extracted 800\n",
      "Extraction took time  0:13:41.448381\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.now()\n",
    "imdb_data['embedding'] = elmo_get_embedding(imdb_data.clean_review.values)\n",
    "print(\"Extraction took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.to_pickle(f\"{data_dir}/imdb_data_w_elmo_embedding.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
