{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0604 19:13:19.210821 140382938605312 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_pickle(f\"{data_dir}/imdb_data.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_set</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>The saddest part of this is the fact that these are 87 minutes I'll never get back. I knew this was terrible from the get-go, with the guy dressed as a lunatic Indian chief on top of the roof. (Se...</td>\n",
       "      <td>tt0077668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie was really stupid and I thought that it wasn't so bad and I could tolerate a movie about a bed eating people. Then the part near the end where the guy has skeleton hands ended up being ...</td>\n",
       "      <td>tt0385639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_set  polarity  \\\n",
       "35859    train         0   \n",
       "2469      test         0   \n",
       "\n",
       "                                                                                                                                                                                                      sentence  \\\n",
       "35859  The saddest part of this is the fact that these are 87 minutes I'll never get back. I knew this was terrible from the get-go, with the guy dressed as a lunatic Indian chief on top of the roof. (Se...   \n",
       "2469   This movie was really stupid and I thought that it wasn't so bad and I could tolerate a movie about a bed eating people. Then the part near the end where the guy has skeleton hands ended up being ...   \n",
       "\n",
       "        movie_id  \n",
       "35859  tt0077668  \n",
       "2469   tt0385639  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = imdb_data.sample(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 128\n",
    "\n",
    "text_http_re  = re.compile(r'http\\S+')\n",
    "text_digit_re = re.compile(r'[0-9]')\n",
    "text_html_re  = re.compile(r'<[^>]{0,20}>')\n",
    "text_punc_re  = re.compile('[' + re.escape('\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~') + ']')\n",
    "text_ws_re    = re.compile('\\s+')\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text_http_re.sub('', text)\n",
    "    text = text_html_re.sub('', text)\n",
    "    text = text_digit_re.sub(' ', text)\n",
    "    text = text_punc_re.sub('', text)\n",
    "    text = text_ws_re.sub(' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)][0:max_words])\n",
    "\n",
    "def process_text(text):\n",
    "    return lemmatize(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['clean_review'] = imdb_data.sentence.apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ELMo Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:19:01.673768 140382938605312 deprecation.py:323] From /anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def batches(sentences, batch_size):\n",
    "    results = []\n",
    "    chunk = []\n",
    "    for s in sentences:\n",
    "        chunk.append(s)\n",
    "        if len(chunk) >= batch_size:\n",
    "            yield(chunk)\n",
    "            chunk = []\n",
    "    if len(chunk) > 0:\n",
    "        yield(chunk)\n",
    "\n",
    "def elmo_create_embedding_extractor(module, batch_size=20):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module, trainable=True)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "        \n",
    "    def extract(_sentences):\n",
    "        results = []\n",
    "        for s_batch in batches(_sentences, batch_size):\n",
    "            results.extend(session.run(embeddings, { sentences: s_batch }))\n",
    "            print(f\"[{datetime.now()}] Extracted {len(results)}\")\n",
    "        return results\n",
    "\n",
    "    return extract\n",
    "\n",
    "elmo_get_embedding = elmo_create_embedding_extractor(\"https://tfhub.dev/google/elmo/2\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-04 19:22:05.545622] Extracted 250\n",
      "[2019-06-04 19:23:07.639448] Extracted 500\n",
      "[2019-06-04 19:24:09.621259] Extracted 750\n",
      "[2019-06-04 19:24:26.948774] Extracted 800\n",
      "Extraction took time  0:03:24.387041\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.now()\n",
    "imdb_data['embedding'] = elmo_get_embedding(imdb_data.clean_review.values)\n",
    "print(\"Extraction took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.to_pickle(f\"{data_dir}/imdb_data_w_elmo_embedding.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
