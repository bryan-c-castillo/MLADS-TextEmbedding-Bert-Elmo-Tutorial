{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0605 05:42:06.724507 140617860892416 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_pickle(f\"{data_dir}/imdb_data.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_set</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>Gayniggers from Outer Space is a short foreign film about black, gay aliens who explore the galaxy until they stumble upon Earth. Being gay, their goal is to have a male-only universe in which all...</td>\n",
       "      <td>tt0274518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the 2007 spy novel by David Ignatius, Body of Lies tells the story of a CIA operative Roger Ferris (DiCaprio) who is sent to Jordan to track down an Al-Qaeda mastermind, all the while tre...</td>\n",
       "      <td>tt0758774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_set  polarity  \\\n",
       "31288    train         0   \n",
       "5967      test         0   \n",
       "\n",
       "                                                                                                                                                                                                      sentence  \\\n",
       "31288  Gayniggers from Outer Space is a short foreign film about black, gay aliens who explore the galaxy until they stumble upon Earth. Being gay, their goal is to have a male-only universe in which all...   \n",
       "5967   Based on the 2007 spy novel by David Ignatius, Body of Lies tells the story of a CIA operative Roger Ferris (DiCaprio) who is sent to Jordan to track down an Al-Qaeda mastermind, all the while tre...   \n",
       "\n",
       "        movie_id  \n",
       "31288  tt0274518  \n",
       "5967   tt0758774  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = imdb_data.sample(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 128\n",
    "\n",
    "text_http_re  = re.compile(r'http\\S+')\n",
    "text_digit_re = re.compile(r'[0-9]')\n",
    "text_html_re  = re.compile(r'<[^>]{0,20}>')\n",
    "text_punc_re  = re.compile('[' + re.escape('\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~') + ']')\n",
    "text_ws_re    = re.compile('\\s+')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text_http_re.sub('', text)\n",
    "    text = text_html_re.sub('', text)\n",
    "    text = text_digit_re.sub(' ', text)\n",
    "    text = text_punc_re.sub('', text)\n",
    "    text = text_ws_re.sub(' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def create_lemmatizer_spacy():\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    def lemmatize(text):\n",
    "        return ' '.join([token.lemma_ for token in nlp(text)][0:max_words])\n",
    "    \n",
    "    return lemmatize\n",
    "\n",
    "def create_lemmatizer_nltk():\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(text):\n",
    "        return ' '.join([lemmatizer.lemmatize(w) for w in text.split()][0:max_words])\n",
    "    \n",
    "    return lemmatize\n",
    "\n",
    "# Setup a lemmatize function, spacy.load may fail on windows for en.\n",
    "try:\n",
    "    lemmatize = create_lemmatizer_spacy()\n",
    "except:\n",
    "    print(\"Using nltk for lemmatization.\")\n",
    "    lemmatize = create_lemmatizer_nltk()\n",
    "            \n",
    "def process_text(text):\n",
    "    return lemmatize(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['clean_review'] = imdb_data.sentence.apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ELMo Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0605 05:42:27.012676 140617860892416 deprecation.py:323] From /anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Utility function to break sentences into batches.\n",
    "def batches(sentences, batch_size):\n",
    "    results = []\n",
    "    chunk = []\n",
    "    for s in sentences:\n",
    "        chunk.append(s)\n",
    "        if len(chunk) >= batch_size:\n",
    "            yield(chunk)\n",
    "            chunk = []\n",
    "    if len(chunk) > 0:\n",
    "        yield(chunk)\n",
    "\n",
    "def elmo_create_embedding_extractor(module, batch_size=20):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module, trainable=True)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "        \n",
    "    def extract(_sentences):\n",
    "        results = []\n",
    "        for s_batch in batches(_sentences, batch_size):\n",
    "            results.extend(session.run(embeddings, { sentences: s_batch }))\n",
    "            print(f\"[{datetime.now()}] Extracted {len(results)}\")\n",
    "        return results\n",
    "\n",
    "    return extract\n",
    "\n",
    "elmo_get_embedding = elmo_create_embedding_extractor(\"https://tfhub.dev/google/elmo/2\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-05 05:42:36.879758] Extracted 50\n",
      "[2019-06-05 05:42:44.167155] Extracted 100\n",
      "[2019-06-05 05:42:51.343977] Extracted 150\n",
      "[2019-06-05 05:42:58.480070] Extracted 200\n",
      "[2019-06-05 05:43:05.660219] Extracted 250\n",
      "[2019-06-05 05:43:12.939412] Extracted 300\n",
      "[2019-06-05 05:43:20.127130] Extracted 350\n",
      "[2019-06-05 05:43:27.281750] Extracted 400\n",
      "[2019-06-05 05:43:34.351196] Extracted 450\n",
      "[2019-06-05 05:43:41.441912] Extracted 500\n",
      "[2019-06-05 05:43:48.537823] Extracted 550\n",
      "[2019-06-05 05:43:55.594576] Extracted 600\n",
      "[2019-06-05 05:44:02.647957] Extracted 650\n",
      "[2019-06-05 05:44:09.644633] Extracted 700\n",
      "[2019-06-05 05:44:16.726220] Extracted 750\n",
      "[2019-06-05 05:44:23.815015] Extracted 800\n",
      "Extraction took time  0:01:55.273435\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.now()\n",
    "imdb_data['embedding'] = elmo_get_embedding(imdb_data.clean_review.values)\n",
    "print(\"Extraction took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.to_pickle(f\"{data_dir}/imdb_data_w_elmo_embedding.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
